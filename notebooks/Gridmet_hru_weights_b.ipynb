{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmcd\\anaconda3\\envs\\gridmet_4\\lib\\site-packages\\dask\\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "C:\\Users\\rmcd\\anaconda3\\envs\\gridmet_4\\lib\\site-packages\\distributed\\config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import glob\n",
    "import zipfile\n",
    "import rasterio\n",
    "import os\n",
    "import xarray as xr\n",
    "import json\n",
    "from rasterstats import zonal_stats\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "\n",
    "# gpd.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B:\\GitRepos\\onhm-fetcher-parser-b\\notebooks\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Gridmet max temperature with geopandas and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B:\\GitRepos\\onhm-fetcher-parser-b\\notebooks\n",
      "..\\Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmcd\\anaconda3\\envs\\gridmet_4\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       LAYER    POI_ID                                           geometry  \\\n",
      "0        NaN   7733855  POLYGON ((-73.37147648799998 41.11232830300003...   \n",
      "1        NaN   7733919  POLYGON ((-73.38531621599998 41.13467480400004...   \n",
      "2        NaN   7732571  POLYGON ((-73.41946539799994 41.16068341300007...   \n",
      "3        NaN   7732387  POLYGON ((-73.41096625099993 41.15832593000005...   \n",
      "4        NaN   7733327  (POLYGON ((-73.28636293699998 41.1278083500000...   \n",
      "5        NaN   7733755  POLYGON ((-73.29794526999996 41.13873439400004...   \n",
      "6        NaN   7732571  POLYGON ((-73.41974626699994 41.16073531300003...   \n",
      "7        NaN   7733923  POLYGON ((-73.41202211999996 41.09592326600006...   \n",
      "8        NaN   7733327  POLYGON ((-73.28641414099997 41.12781781200005...   \n",
      "9        NaN   7733755  POLYGON ((-73.29405337099996 41.16091992900004...   \n",
      "10       NaN   7734265  POLYGON ((-73.23675659799994 41.15356137800006...   \n",
      "11       NaN   7733789  POLYGON ((-73.25943116699995 41.15905835700005...   \n",
      "12       NaN   7734279  (POLYGON ((-73.29891329499998 41.1245696720000...   \n",
      "13       NaN   7732571  POLYGON ((-73.41096625099993 41.15832593000005...   \n",
      "14       NaN   7732439  POLYGON ((-73.22927216099998 41.15827253100008...   \n",
      "15       NaN   7732355  POLYGON ((-73.27023118599993 41.16571362300004...   \n",
      "16       NaN   7732355  POLYGON ((-73.25943116699995 41.15905835700005...   \n",
      "17       NaN   7733789  POLYGON ((-73.28610354099999 41.19422987200005...   \n",
      "18       NaN   7732439  POLYGON ((-73.23197144699998 41.15876127800004...   \n",
      "19       NaN   7733919  POLYGON ((-73.48544443099996 41.27261428000003...   \n",
      "20       NaN   7733923  (POLYGON ((-73.41184187799996 41.0958206220000...   \n",
      "21       NaN   7733853  POLYGON ((-73.37134955199997 41.11230484700008...   \n",
      "22       NaN   7731677  POLYGON ((-73.39206279699994 41.28865065800005...   \n",
      "23       NaN   7731717  POLYGON ((-73.48166788099996 41.30364303300007...   \n",
      "24       NaN   7731717  POLYGON ((-73.49208958599996 41.31613667400006...   \n",
      "25       NaN   7732387  POLYGON ((-73.47001744299996 41.31309839500005...   \n",
      "26       NaN   7731593  POLYGON ((-73.47033871799994 41.31333882700005...   \n",
      "27       NaN   7732387  POLYGON ((-73.40944800799997 41.28019790200005...   \n",
      "28       NaN   7732387  POLYGON ((-73.47261941699998 41.31773452900006...   \n",
      "29       NaN   7731677  POLYGON ((-73.39206279699994 41.28865065800005...   \n",
      "...      ...       ...                                                ...   \n",
      "109921   NaN   8241316  POLYGON ((-123.4183258689999 41.03385673400004...   \n",
      "109922   NaN   8242198  POLYGON ((-122.93519441 41.17699567100004, -12...   \n",
      "109923   NaN   8242198  POLYGON ((-122.919557415 41.14660930500003, -1...   \n",
      "109924   NaN   8316419  POLYGON ((-123.912703073 41.00572711200005, -1...   \n",
      "109925   NaN   8318059  POLYGON ((-123.937925854 41.00032168300004, -1...   \n",
      "109926   NaN   8318059  POLYGON ((-123.951208631 40.99788409100006, -1...   \n",
      "109927   NaN   8316419  POLYGON ((-123.93152028 41.01321257700005, -12...   \n",
      "109928   NaN   3799627  (POLYGON ((-122.624937448 41.45819612700006, -...   \n",
      "109929   NaN   3799627  POLYGON ((-122.681485858 41.54056923100006, -1...   \n",
      "109930   NaN   8257419  POLYGON ((-123.171331878 41.45996228400003, -1...   \n",
      "109931   NaN   8257419  POLYGON ((-123.156461453 41.43749769400006, -1...   \n",
      "109932   NaN   4441306  (POLYGON ((-123.766195848 41.39543280900006, -...   \n",
      "109933   NaN   4441306  POLYGON ((-123.7666459819999 41.39561209900006...   \n",
      "109934   NaN   3798343  POLYGON ((-123.029132955 41.56973733600006, -1...   \n",
      "109935   NaN   8256571  POLYGON ((-123.138853554 41.53882352900007, -1...   \n",
      "109936   NaN   3798401  POLYGON ((-123.083709334 41.51207290400004, -1...   \n",
      "109937   NaN   3798401  POLYGON ((-123.083709334 41.51207290400004, -1...   \n",
      "109938   NaN   3798343  POLYGON ((-123.029132955 41.56973733600006, -1...   \n",
      "109939   NaN   8256571  POLYGON ((-123.124624726 41.50866834600004, -1...   \n",
      "109940   NaN   3917130  POLYGON ((-122.233229063 41.76221992600006, -1...   \n",
      "109941   NaN   8315603  (POLYGON ((-124.0098100819999 41.4111417110000...   \n",
      "109942   NaN   8315603  POLYGON ((-124.039618137 41.45065053100006, -1...   \n",
      "109943   NaN   4439566  POLYGON ((-123.680777171 41.63411462500005, -1...   \n",
      "109944   NaN   4439814  POLYGON ((-123.688948246 41.58332955700007, -1...   \n",
      "109945   NaN   4439566  POLYGON ((-123.652291099 41.61551570800003, -1...   \n",
      "109946   NaN   4439814  POLYGON ((-123.682760808 41.59421288900006, -1...   \n",
      "109947   NaN   2551733  (POLYGON ((-121.3264525819999 42.3195167990000...   \n",
      "109948   NaN   2551733  POLYGON ((-121.149442958 42.23413625600006, -1...   \n",
      "109949   NaN  24081601  POLYGON ((-121.441435272 42.80623224900006, -1...   \n",
      "109950   NaN  24081601  (POLYGON ((-121.351904323 42.77765434300005, -...   \n",
      "\n",
      "        hru_id_nat  hru_id_reg region  \n",
      "0                1           1     01  \n",
      "1                2           2     01  \n",
      "2                3           3     01  \n",
      "3                4           4     01  \n",
      "4                5           5     01  \n",
      "5                6           6     01  \n",
      "6                7           7     01  \n",
      "7                8           8     01  \n",
      "8                9           9     01  \n",
      "9               10          10     01  \n",
      "10              11          11     01  \n",
      "11              12          12     01  \n",
      "12              13          13     01  \n",
      "13              14          14     01  \n",
      "14              15          15     01  \n",
      "15              16          16     01  \n",
      "16              17          17     01  \n",
      "17              18          18     01  \n",
      "18              19          19     01  \n",
      "19              20          20     01  \n",
      "20              21          21     01  \n",
      "21              22          22     01  \n",
      "22              23          23     01  \n",
      "23              24          24     01  \n",
      "24              25          25     01  \n",
      "25              26          26     01  \n",
      "26              27          27     01  \n",
      "27              28          28     01  \n",
      "28              29          29     01  \n",
      "29              30          30     01  \n",
      "...            ...         ...    ...  \n",
      "109921      109922        5808     18  \n",
      "109922      109923        5809     18  \n",
      "109923      109924        5810     18  \n",
      "109924      109925        5811     18  \n",
      "109925      109926        5812     18  \n",
      "109926      109927        5813     18  \n",
      "109927      109928        5814     18  \n",
      "109928      109929        5815     18  \n",
      "109929      109930        5816     18  \n",
      "109930      109931        5817     18  \n",
      "109931      109932        5818     18  \n",
      "109932      109933        5819     18  \n",
      "109933      109934        5820     18  \n",
      "109934      109935        5821     18  \n",
      "109935      109936        5822     18  \n",
      "109936      109937        5823     18  \n",
      "109937      109938        5824     18  \n",
      "109938      109939        5825     18  \n",
      "109939      109940        5826     18  \n",
      "109940      109941        5827     18  \n",
      "109941      109942        5828     18  \n",
      "109942      109943        5829     18  \n",
      "109943      109944        5830     18  \n",
      "109944      109945        5831     18  \n",
      "109945      109946        5832     18  \n",
      "109946      109947        5833     18  \n",
      "109947      109948        5834     18  \n",
      "109948      109949        5835     18  \n",
      "109949      109950        5836     18  \n",
      "109950      109951        5837     18  \n",
      "\n",
      "[109951 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "from pathlib import Path\n",
    "folder = Path(r'../Data') # assumes working directory is onhm-fetcher-parser\n",
    "print(folder)\n",
    "#shapefiles = folder.glob(\"*_0[1-2].shp\")\n",
    "shapefiles = folder.glob(\"*.shp\")\n",
    "gdf = pd.concat([\n",
    "    gpd.read_file(shp)\n",
    "    for shp in shapefiles\n",
    "]).pipe(gpd.GeoDataFrame)\n",
    "gdf.reset_index(drop=True, inplace=True)\n",
    "# gdf.plot()\n",
    "print(gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Gridmet data (as netcdf file) print out some metadata\n",
    "This first bit of code follows examples from the following link:https://climate.northwestknowledge.net/MACA/OPENDAP.php\n",
    "First we open the data set and inspect the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://thredds.northwestknowledge.net:8080/thredds/dodsC/MET/tmmx/tmmx_2019.nc\n",
      "<xarray.Dataset>\n",
      "Dimensions:          (crs: 1, day: 227, lat: 585, lon: 1386)\n",
      "Coordinates:\n",
      "  * lat              (lat) float64 49.4 49.36 49.32 49.28 ... 25.15 25.11 25.07\n",
      "  * day              (day) datetime64[ns] 2019-01-01 2019-01-02 ... 2019-08-15\n",
      "  * crs              (crs) float32 3.0\n",
      "  * lon              (lon) float64 -124.8 -124.7 -124.7 ... -67.14 -67.1 -67.06\n",
      "Data variables:\n",
      "    air_temperature  (day, lat, lon) float32 ...\n",
      "Attributes:\n",
      "    geospatial_bounds_crs:      EPSG:4326\n",
      "    Conventions:                CF-1.6\n",
      "    geospatial_bounds:          POLYGON((-124.7666666333333 49.40000000000000...\n",
      "    geospatial_lat_min:         25.066666666666666\n",
      "    geospatial_lat_max:         49.40000000000000\n",
      "    geospatial_lon_min:         -124.7666666333333\n",
      "    geospatial_lon_max:         -67.058333300000015\n",
      "    geospatial_lon_resolution:  0.041666666666666\n",
      "    geospatial_lat_resolution:  0.041666666666666\n",
      "    geospatial_lat_units:       decimal_degrees north\n",
      "    geospatial_lon_units:       decimal_degrees east\n",
      "    coordinate_system:          EPSG:4326\n",
      "    author:                     John Abatzoglou - University of Idaho, jabatz...\n",
      "    date:                       16 August 2019\n",
      "    note1:                      The projection information for this file is: ...\n",
      "    note2:                      Citation: Abatzoglou, J.T., 2013, Development...\n",
      "    last_permanent_slice:       167\n",
      "    last_early_slice:           227\n",
      "    last_provisional_slice:     221\n",
      "    note3:                      Data in slices after last_permanent_slice (1-...\n",
      "    note4:                      Data in slices after last_provisional_slice (...\n",
      "    note5:                      Days correspond approximately to calendar day...\n",
      "\n",
      " The meta data is: \n",
      " {\n",
      "    \"geospatial_bounds_crs\": \"EPSG:4326\",\n",
      "    \"Conventions\": \"CF-1.6\",\n",
      "    \"geospatial_bounds\": \"POLYGON((-124.7666666333333 49.400000000000000, -124.7666666333333 25.066666666666666, -67.058333300000015 25.066666666666666, -67.058333300000015 49.400000000000000, -124.7666666333333 49.400000000000000))\",\n",
      "    \"geospatial_lat_min\": \"25.066666666666666\",\n",
      "    \"geospatial_lat_max\": \"49.40000000000000\",\n",
      "    \"geospatial_lon_min\": \"-124.7666666333333\",\n",
      "    \"geospatial_lon_max\": \"-67.058333300000015\",\n",
      "    \"geospatial_lon_resolution\": \"0.041666666666666\",\n",
      "    \"geospatial_lat_resolution\": \"0.041666666666666\",\n",
      "    \"geospatial_lat_units\": \"decimal_degrees north\",\n",
      "    \"geospatial_lon_units\": \"decimal_degrees east\",\n",
      "    \"coordinate_system\": \"EPSG:4326\",\n",
      "    \"author\": \"John Abatzoglou - University of Idaho, jabatzoglou@uidaho.edu\",\n",
      "    \"date\": \"16 August 2019\",\n",
      "    \"note1\": \"The projection information for this file is: GCS WGS 1984.\",\n",
      "    \"note2\": \"Citation: Abatzoglou, J.T., 2013, Development of gridded surface meteorological data for ecological applications and modeling, International Journal of Climatology, DOI: 10.1002/joc.3413\",\n",
      "    \"last_permanent_slice\": \"167\",\n",
      "    \"last_early_slice\": \"227\",\n",
      "    \"last_provisional_slice\": \"221\",\n",
      "    \"note3\": \"Data in slices after last_permanent_slice (1-based) are considered provisional and subject to change with subsequent updates\",\n",
      "    \"note4\": \"Data in slices after last_provisional_slice (1-based) are considered early and subject to change with subsequent updates\",\n",
      "    \"note5\": \"Days correspond approximately to calendar days ending at midnight, Mountain Standard Time (7 UTC the next calendar day)\"\n",
      "}\n",
      "\n",
      " Data attributes, sizes, and coords \n",
      "\n",
      "\n",
      " Data sizes are: \n",
      " Frozen(OrderedDict([('day', 227), ('lat', 585), ('lon', 1386)]))\n",
      "\n",
      " Data coords are: \n",
      " Coordinates:\n",
      "  * lat      (lat) float64 49.4 49.36 49.32 49.28 ... 25.19 25.15 25.11 25.07\n",
      "  * day      (day) datetime64[ns] 2019-01-01 2019-01-02 ... 2019-08-15\n",
      "  * lon      (lon) float64 -124.8 -124.7 -124.7 -124.6 ... -67.14 -67.1 -67.06\n",
      "<class 'xarray.core.utils.Frozen'>\n",
      "227\n",
      "227 1386 585\n"
     ]
    }
   ],
   "source": [
    "#=========================================================\n",
    "#            MACAV2METDATA FILE PARAMETERS\n",
    "#=========================================================\n",
    "dirPath='http://thredds.northwestknowledge.net:8080'\n",
    "fileName='/thredds/dodsC/MET/tmmx/tmmx_2019.nc'\n",
    "\n",
    "#--------------------------------------------------------\n",
    "#   FORM FILENAME AND GET HANDLE TO FILE AND DATA\n",
    "#--------------------------------------------------------\n",
    "fullfilename= dirPath+fileName\n",
    "print(fullfilename)\n",
    "\n",
    "ds = xr.open_dataset(fullfilename)\n",
    "\n",
    "print(ds)\n",
    "\n",
    "# df = ds.to_dataframe()\n",
    "\n",
    "print('\\n The meta data is: \\n', json.dumps(ds.attrs, indent=4))\n",
    "lathandle=ds['lat']\n",
    "lonhandle=ds['lon']\n",
    "timehandle=ds['day']\n",
    "datahandle=ds['air_temperature']\n",
    "crshandle=ds['crs']\n",
    "# print('\\n The crs meta data is \\n', json.dumps(crshandle.attrs, indent=4))\n",
    "\n",
    "# crstransform = crshandle.attrs['GeoTransform']\n",
    "# print(crstransform)\n",
    "\n",
    "#collect data to describe geotransform\n",
    "lonmin = float(ds.attrs['geospatial_lon_min'])\n",
    "latmax = float(ds.attrs['geospatial_lat_max'])\n",
    "lonres = float(ds.attrs['geospatial_lon_resolution'])\n",
    "latres = float(ds.attrs['geospatial_lon_resolution'])\n",
    "\n",
    "#Print some information on the data\n",
    "\n",
    "print('\\n Data attributes, sizes, and coords \\n') \n",
    "# print('\\n Data attributes are: \\n', json.dumps(datahandle.attrs, indent=4))\n",
    "print('\\n Data sizes are: \\n', datahandle.sizes)\n",
    "print('\\n Data coords are: \\n', datahandle.coords)\n",
    "\n",
    "ts = datahandle.sizes\n",
    "print(type(ts))\n",
    "print(ts['day'])\n",
    "dayshape = ts['day']\n",
    "Lonshape = ts['lon']\n",
    "Latshape = ts['lat']\n",
    "#dayshape,lonshape,latshape = datahandle.values.shape\n",
    "print(dayshape, Lonshape, Latshape)\n",
    "\n",
    "# datahandle.values[dayshape-1,:,:].shape\n",
    "\n",
    "# print(lathandle.values.shape)\n",
    "# print(type(lathandle.values))\n",
    "# print(datahandle.dtype)\n",
    "# print(np.isfortran(datahandle.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'air_temperature' ()>\n",
      "array(nan, dtype=float32)\n",
      "Coordinates:\n",
      "    lat      float64 29.4\n",
      "    day      datetime64[ns] 2019-08-15\n",
      "    lon      float64 -73.43\n",
      "Attributes:\n",
      "    units:              K\n",
      "    description:        Daily Maximum Temperature\n",
      "    long_name:          tmmx\n",
      "    standard_name:      tmmx\n",
      "    dimensions:         lon lat time\n",
      "    grid_mapping:       crs\n",
      "    coordinate_system:  WGS84,EPSG:4326\n",
      "    _ChunkSizes:        [ 46 117 278]\n"
     ]
    }
   ],
   "source": [
    "print(datahandle[dayshape-1, 480, 1232])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add netcdf data (tmax here) to dataframe that has hru id and geometry\n",
    "* use weight file to assign tmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testnan(value, weight):\n",
    "    if np.isnan(value): \n",
    "        tvalue = 0.0\n",
    "        tweight = 0.0\n",
    "    else:\n",
    "        tvalue = value\n",
    "        tweight = weight\n",
    "    return tvalue, tweight\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(data))\n",
    "# print(data.shape)\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with Pandas groupby alternative to original method in following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   grid_ids  hru_id_nat         w\n",
      "0    278433           1  0.000120\n",
      "1    277046           1  0.031155\n",
      "2    277047           1  0.901587\n",
      "3    277048           1  0.046570\n",
      "4    275661           1  0.020568\n",
      "[nan nan nan ... nan nan nan]\n",
      "109951 109951\n",
      "<class 'numpy.float64'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmcd\\anaconda3\\envs\\gridmet_4\\lib\\site-packages\\ipykernel_launcher.py:45: UserWarning: Warning: converting a masked element to nan.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min/max 7.059214550694037 48.20001220703125\n"
     ]
    }
   ],
   "source": [
    "# add tmax column to dataframe\n",
    "gdf['tmax']=0.0\n",
    "\n",
    "#open weight data\n",
    "# wght_df = pd.read_csv('../Data/hru_metdata_weights.csv')\n",
    "# wght_df_40 = pd.read_csv('../Data/hru_metdata_weights_40m.csv')\n",
    "# wght_df_500 = pd.read_csv('../Data/hru_metdata_weights_500m.csv')\n",
    "# wght_UofI = pd.read_csv('../Data/hru_uofimetdata_weights.csv')\n",
    "wght_UofI = pd.read_csv('weights.csv')\n",
    "# print(len(wght_df['hru_id_nat'].unique()), len(wght_df_40['hru_id_nat'].unique()), \n",
    "#       len(wght_df_500['hru_id_nat'].unique()), len(wght_UofI['hru_id_nat'].unique()))\n",
    "print(wght_UofI.head())\n",
    "\n",
    "#iterate through hru's, grab all weights associated with hru_id, get total weighted value from netcdf file, assign to tmax\n",
    "ndata = datahandle.values[dayshape-1,:,:].flatten(order='K')\n",
    "# ndata=np.nan_to_num(data)\n",
    "print(ndata[1000:])\n",
    "# def w_mean(data)\n",
    "unique_hru_ids = wght_UofI.groupby('hru_id_nat')\n",
    "print(len(gdf), len(unique_hru_ids))\n",
    "\n",
    "def get_wval(grp, ndata):\n",
    "    ttmax = twght = 0.0\n",
    "    for index, row in grp.iterrows():\n",
    "        ttmax += row['w']*ndata[np.int(row['grid_ids'])]\n",
    "        twght += row['w']\n",
    "    return ttmax/twght\n",
    "def np_get_wval(grp, ndata):\n",
    "    return np.average(ndata[grp['grid_ids'].values.astype(int)], weights=grp['w'])\n",
    "def np_get_wval2(grp, ndata):\n",
    "    mdata = np.ma.masked_array(ndata[grp['grid_ids'].values.astype(int)], np.isnan(ndata[grp['grid_ids'].values.astype(int)]))\n",
    "    return np.ma.average(mdata, weights=grp['w'])\n",
    "#     return np.average(ndata[grp['grid_ids'].values.astype(int)], weights=grp['w'])\n",
    "    \n",
    "# unique_hru_ids.get_group(gdf['hru_id_nat']).agg({'tmax': np_get_wval(weight_id_rows, ndata)})    \n",
    "td = np.zeros(len(gdf.index))\n",
    "for index, row in gdf.iterrows():\n",
    "    weight_id_rows = unique_hru_ids.get_group(row['hru_id_nat'])\n",
    "#     print(weight_id_rows['grid_ids'].values.astype(int))\n",
    "#     unique_hru_ids.get_group(row['hru_id_nat']).agg({'tmax': np_get_wval(weight_id_rows, ndata)})\n",
    "#     gdf.loc[gdf.index[index],'tmax'] = np_get_wval(weight_id_rows, ndata)-273.5\n",
    "    tmp = np_get_wval2(weight_id_rows, ndata)-273.5\n",
    "    if index == 1:\n",
    "        print(type(tmp))\n",
    "    td[index] = np_get_wval2(weight_id_rows, ndata)-273.5\n",
    "#     if td[index] < 0.0:\n",
    "#         print(ndata[weight_id_rows['grid_ids'].values.astype(int)], weight_id_rows['w'])\n",
    "#     print(index, td[index])\n",
    "#     if row['hru_id_nat'] == 829:\n",
    "#         print(\"in test\")\n",
    "#         for i2, el in weight_id_rows.iterrows():\n",
    "#             print(el['w'], ndata[el['grid_ids'].astype(int)])\n",
    "#         print(np.average(ndata[weight_id_rows['grid_ids'].values.astype(int)], weights=weight_id_rows['w'])-273.5)\n",
    "#     print(index, row['hru_id_nat'], np_get_wval(weight_id_rows, ndata)-273.5)\n",
    "#     gdf.loc[gdf.index[index], 'tmax'] =\n",
    "# #     print(get_wval(weight_id_rows, ndata)-273.5)\n",
    "# #     row.loc['tmax']=get_wval(weight_id_rows, ndata)-273.5\n",
    "# #     gdf.loc[gdf.index[index], 'tmax'] = get_wval(weight_id_rows, ndata)-273.5\n",
    "# print(len(td))\n",
    "# gdf['tmax'] = gpd.GeoSeries([np.transpose(td)], index=gdf.index)\n",
    "gdf['tmax'] = td.tolist()\n",
    "gdf['tmax'].fillna(0.0)\n",
    "# print(td.tolist())\n",
    "print('min/max', gdf['tmax'].min(), gdf['tmax'].max())\n",
    "# print(gdf)\n",
    "# gdf.plot(figsize=(12,12), column = 'tmax',linewidth=0.25, edgecolor='white')    \n",
    "# print(gdf.groupby(tmax).min)\n",
    "# f, ax = plt.subplots(2, figsize=(12,12))\n",
    "# gdf.plot(ax=ax[0], column = 'tmax',linewidth=0., edgecolor='white', scheme='quantiles')\n",
    "# ptmax = ds.air_temperature-273.5\n",
    "# ptmax_1 = ptmax.isel(day=dayshape-1)\n",
    "# lvs = np.arange(gdf['tmax'].min(), gdf['tmax'].max(), 0.5)\n",
    "# ptmax_1.plot(ax=ax[1], levels=lvs, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(unique_hru_ids.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmcd\\anaconda3\\envs\\gridmet_4\\lib\\site-packages\\matplotlib\\colors.py:512: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n"
     ]
    }
   ],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "f, ax = plt.subplots(1)\n",
    "ax.set_aspect('equal')\n",
    "# ax.axis('equal')\n",
    "# ax1.set(xlim=(-130, -60), ylim=(20, 55))\n",
    "# divider_0 = make_axes_locatable(ax[0])\n",
    "# cax_0 = divider_0.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "lvs = np.arange(gdf['tmax'].min(), gdf['tmax'].max(), 0.1)\n",
    "gdf.plot(ax=ax, column = 'tmax',linewidth=0., edgecolor='white', cmap='viridis', k=20)\n",
    "f.savefig('hru.png')\n",
    "f.tight_layout()\n",
    "f1, ax1 = plt.subplots(1)\n",
    "ax1.set_aspect('equal')\n",
    "# ax1.set(xlim=(-130, -60), ylim=(20, 55))\n",
    "ptmax = ds.air_temperature-273.5\n",
    "ptmax_1 = ptmax.isel(day=dayshape-1)\n",
    "ptmax_1.plot(ax=ax1, levels=lvs, cmap='viridis')\n",
    "f1.tight_layout()\n",
    "f1.savefig('gridmet.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(ptmax_1))\n",
    "print(type(gdf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add tmax column to dataframe\n",
    "gdf['tmax']=None\n",
    "\n",
    "#open weight data\n",
    "wght_df = pd.read_csv('../Data/hru_metdata_weights.csv')\n",
    "wght_df_40 = pd.read_csv('../Data/hru_metdata_weights_40m.csv')\n",
    "wght_df_500 = pd.read_csv('../Data/hru_metdata_weights_500m.csv')\n",
    "wght_UofI = pd.read_csv('../Data/hru_uofimetdata_weights.csv')\n",
    "print(len(wght_df['hru_id_nat'].unique()), len(wght_df_40['hru_id_nat'].unique()), len(wght_df_500['hru_id_nat'].unique()))\n",
    "print(wght_df.head())\n",
    "\n",
    "#iterate through hru's, grab all weights associated with hru_id, get total weighted value from netcdf file, assign to tmax\n",
    "unique_hru_ids = wght_UofI['hru_id_nat'].unique()\n",
    "print(len(gdf), len(unique_hru_ids))\n",
    "ndata=datahandle.values[dayshape-1,:,:].flatten(order='C')\n",
    "for index, row in gdf.iterrows():\n",
    "    weight_id_rows = wght_UofI.loc[wght_UofI['hru_id_nat'] == row['hru_id_nat']]\n",
    "    ttmax = 0.0\n",
    "    twght = 0.0\n",
    "    tcount = 0\n",
    "    # based on above metadata the shape of the netcdf file is day,lat(y),lon(x)\n",
    "    for ind2, rw2 in weight_id_rows.iterrows():\n",
    "#           print(rw2['Y_ind'],rw2['X_ind'])\n",
    "#         tval, twt = testnan(datahandle.values[dayshape-1,int(rw2['Y_ind']),int(rw2['X_ind'])], rw2['w'])\n",
    "        tval, twt = testnan(ndata[rw2['grid_ids'].astype(int)], rw2['w'])\n",
    "        if twt > 0.0:\n",
    "            ttmax += twt*tval\n",
    "            twght += twt\n",
    "            tcount += 1\n",
    "#           if index == 4512: # test that discovered some weights associated with intesecting cells that are outside conus and return nan values\n",
    "#               print(ind2, rw2['w'], ttmax, twght, tcount, datahandle.values[dayshape-1,int(rw2['Y_ind']),int(rw2['X_ind'])], rw2['Y_ind'], rw2['X_ind'])\n",
    "    print(index, row['hru_id_nat'], tcount, ttmax, twght, ((ttmax/twght)-273.15))\n",
    "    gdf.loc[gdf.index[index], 'tmax'] = ((ttmax/twght)-273.15)\n",
    "#         data.setvalue(index, 'tmax', ((ttmax/twght)-273.15) * 9/5 + 32)\n",
    "#         print('tmp', hru_id, row['tmax'])\n",
    "# print(gdf)\n",
    "# gdf.plot()\n",
    "# f, ax = plt.subplots(2, figsize=(8,6))\n",
    "# gdf.plot(ax=ax[0], column = 'tmax')\n",
    "# ptmax = ds.air_temperature-273.5\n",
    "# ptmax_1 = ptmax.isel(day=dayshape-1)\n",
    "# ptmax_1.plot(ax=ax[1], levels=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert netcdf to geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = lathandle.values\n",
    "lon = lonhandle.values\n",
    "\n",
    "transform = from_origin( lonmin, latmax, lonres, latres)\n",
    "# res = (lon[-1] - lon[0])/lon.shape[0]\n",
    "# print(res)\n",
    "# transform2 = from_origin(lon[0]-res/2, lat[-1]+res/2, res, res) \n",
    "# print(transform, transform2)\n",
    "new_dataset = rasterio.open(r'C:\\Users\\rmcd\\Documents\\oNHM\\GeospatialFabric_1\\nhru\\unzip\\test1.tif', 'w', driver='GTiff',\n",
    "                            height = lonshape, width = latshape,\n",
    "                            count=1, dtype=str(datahandle.dtype),\n",
    "                            crs={'init': 'epsg:4326'},\n",
    "                            transform=transform)\n",
    "# vals = np.transpose(datahandle.values, [1,2,0])\n",
    "# vals2 = vals[:,:,85-1]\n",
    "vals = datahandle.values[dayshape-1, :, :]\n",
    "print(vals.shape)\n",
    "# im = np.transpose(vals, [1,2,0])\n",
    "# fa = np.asfortranarray(vals)\n",
    "# ca = np.asanyarray(vals, order='C')\n",
    "ud = (np.flipud(vals)-273.15) * 9/5 + 32\n",
    "# at = np.transpose(vals)\n",
    "# atf = np.rot90(at)\n",
    "new_dataset.write(ud, 1)\n",
    "# new_dataset.warp.transform\n",
    "# print(new_dataset.transform)\n",
    "# pyplot.imshow(new_dataset.read(1), cmap='pink')\n",
    "# pyplot.show()\n",
    "print(new_dataset)\n",
    "new_dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot geotiff raster data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\rmcd\\Documents\\oNHM\\GeospatialFabric_1\\nhru\\unzip')\n",
    "with rasterio.open(r'test1.tif') as src:\n",
    "    transform = src.meta['transform']\n",
    "    print(type(transform), src.meta)\n",
    "    array = src.read(1)\n",
    "print(src)\n",
    "plt.imshow(array, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('max temp')\n",
    "plt.show()\n",
    "src.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform zonal stats using rasterstats with the geotiff raster and hru shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geoplot as gplt\n",
    "\n",
    "print(transform)\n",
    "with rasterio.open(r'test1.tif') as src:\n",
    "    transform = src.meta['transform']\n",
    "    print(type(transform), src.meta)\n",
    "    array = src.read(1)\n",
    "\n",
    "hrudata = gpd.GeoDataFrame.from_file(r'nhru_02.shp')\n",
    "\n",
    "stats = zonal_stats(hrudata, array, transform=transform.to_gdal(), prefix='tmax_', all_touched=True)\n",
    "statsdf = pd.DataFrame(stats)\n",
    "src.close()\n",
    "\n",
    "print(statsdf.head())\n",
    "\n",
    "zonalhru = hrudata.join(statsdf)\n",
    "\n",
    "# # print(stats)\n",
    "# # newhru = hrudata.join(gpd.DataFrame(stats))\n",
    "# # print(newhru.head())\n",
    "zonalhru.__class__ = gpd.GeoDataFrame\n",
    "zonalhru.crs={}\n",
    "zonalhru.set_geometry('geometry')\n",
    "# ax = gplt.pointplot(zonalhru['mean'])\n",
    "# gplt.polyplot()\n",
    "# geoplot.choropleth(zonalhru, hue='mean', cmap='viridis', k = 20, \n",
    "#                 linewidth=0.5, legend=True)\n",
    "zonalhru.plot(column='tmax_mean', cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Rasterstats method: \n",
    "* https://geohackweek.github.io/vector/06-geopandas-advanced/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import rasterio.plot as rioplot\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# print(transform)\n",
    "with rasterio.open(r'test1.tif') as src:\n",
    "    transformb = src.meta['transform']\n",
    "    print(type(transformb), src.meta)\n",
    "    array = src.read(1)\n",
    "rasterdata = rasterio.open(r'test1.tif')\n",
    "tmp = rioplot.show(rasterdata, with_bounds=True, cmap='viridis', extent=([-82, -70, 36, 46]))\n",
    "print(tmp.axis)\n",
    "tmp.set_xlim([-82, -70])\n",
    "tmp.set_ylim([36, 46])\n",
    "hrudata = gpd.GeoDataFrame.from_file(r'nhru_02.shp')\n",
    "\n",
    "stats = zonal_stats(hrudata, r'test1.tif', transform=transformb.to_gdal(), prefix='tmax_', \n",
    "                    all_touched=True, geojson_out=True)\n",
    "# statsdf = pd.DataFrame(stats)\n",
    "# src.close()\n",
    "stats_gdf = gpd.GeoDataFrame.from_features(stats)\n",
    "print(stats_gdf.head())\n",
    "extent=([-82, -70, 36, 46])\n",
    "f, ax = plt.subplots(1, figsize=(8,6))\n",
    "ax.set_title(\"max temp\")\n",
    "stats_gdf.plot(ax=ax, column='tmax_mean', scheme='Equal_Interval', k=10, \n",
    "                   cmap='viridis', linewidth=0.25, edgecolor='black', \n",
    "                   legend=True, legend_kwds={'loc': 'upper left'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(stats_gdf.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write netcdf file using netcdf4\n",
    "* https://github.com/Unidata/netcdf4-python/blob/master/examples/writing_netCDF.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "try: ncfile.close() # just to be safe, make sure dataset is not already open.\n",
    "except: pass\n",
    "ncfile = netCDF4.Dataset('new.nc',mode='w',format='NETCDF4_CLASSIC')\n",
    "\n",
    "# Global Attributes\n",
    "ncfile.Conventions = 'CF-1.8'\n",
    "ncfile.featureType = 'timeSeries'\n",
    "ncfile.history = ''\n",
    "\n",
    "sp_dim = len(stats_gdf.index)\n",
    "hruid_dim = ncfile.createDimension('hruid', sp_dim)     # hru_id\n",
    "time_dim = ncfile.createDimension('time', None) # unlimited axis (can be appended to).\n",
    "for dim in ncfile.dimensions.items():\n",
    "    print(dim)\n",
    "\n",
    "#Create Variables\n",
    "time = ncfile.createVariable('time', np.int, ('time', ))\n",
    "time.long_name = 'time'\n",
    "time.standard_name = 'time'\n",
    "time.units = 'days since '+'base_date'+' 00:00'+'time_zone'\n",
    "\n",
    "hru = ncfile.createVariable('hruid', np.int, ('hruid', ))\n",
    "hru.cf_role = 'timeseries_id'\n",
    "hru.long_name = 'local model hru id'\n",
    "\n",
    "lat = ncfile.createVariable('hru_lat', np.float32, ('hruid',))\n",
    "lat.long_name = 'Latitude of HRU centroid'\n",
    "lat.units = 'degrees_north'\n",
    "lat.standard_name = 'hru_latitude'\n",
    "\n",
    "lon = ncfile.createVariable('hru_lon', np.float32, ('hruid',))\n",
    "lon.long_name = 'Longitude of HRU centroid'\n",
    "lon.units = 'degrees_east'\n",
    "lon.standard_name = 'hru_longitude'\n",
    "\n",
    "prcp = ncfile.createVariable('prcp', np.float32, ('time', 'hruid'))\n",
    "prcp.long_name = 'Daily precipitation rate'\n",
    "prcp.units = 'mm/day'\n",
    "prcp.standard_name = 'lwe_precipitation_rate'\n",
    "\n",
    "tmax = ncfile.createVariable('tmax', np.float32, ('time', 'hruid'))\n",
    "tmax.long_name = 'Maximum daily air temperature'\n",
    "tmax.units = 'degree_Celsius'\n",
    "tmax.standard_name = 'maximum_daily_air_temperature'\n",
    "\n",
    "tmin = ncfile.createVariable('tmin', np.float32, ('time', 'hruid'))\n",
    "tmin.long_name = 'Minimum daily air temperature'\n",
    "tmin.units = 'degree_Celsius'\n",
    "tmin.standard_name = 'minimum_daily_air_temperature'\n",
    "\n",
    "# fill variables with available data\n",
    "def getXY(pt):\n",
    "    return (pt.x, pt.y)\n",
    "centroidseries = stats_gdf['geometry'].centroid\n",
    "tlon, tlat = [list(t) for t  in zip(*map(getXY, centroidseries))]\n",
    "# print(lon, lat)\n",
    "lon[:] = tlon\n",
    "lat[:] = tlat\n",
    "hru[:] = stats_gdf['hru_id_nat'].values\n",
    "# print(hruid)\n",
    "tmax[0,:] = stats_gdf['tmax_mean'].values\n",
    "\n",
    "print(ncfile)\n",
    "ncfile.close(); print(\"dataset is closed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
