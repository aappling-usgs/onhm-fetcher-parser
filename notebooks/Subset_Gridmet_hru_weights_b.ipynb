{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import glob\n",
    "import zipfile\n",
    "import rasterio\n",
    "import os\n",
    "import xarray as xr\n",
    "import json\n",
    "from rasterstats import zonal_stats\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "\n",
    "# gpd.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B:\\GitRepos\\onhm-fetcher-parser-b\\notebooks\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Gridmet max temperature with geopandas and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B:\\GitRepos\\onhm-fetcher-parser\\notebooks\n",
      "..\\Data_v1_1\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "from pathlib import Path\n",
    "folder = Path(r'../Data_v1_1') # assumes working directory is onhm-fetcher-parser\n",
    "print(folder)\n",
    "# shapefiles = folder.glob(\"*_0[1-2].shp\")\n",
    "shapefiles = folder.glob(\"*.shp\")\n",
    "gdf = pd.concat([\n",
    "    gpd.read_file(shp)\n",
    "    for shp in shapefiles\n",
    "]).pipe(gpd.GeoDataFrame)\n",
    "gdf.reset_index(drop=True, inplace=True)\n",
    "# gdf.plot()\n",
    "#print(gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some testing with datetime to add to requests below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.datetime'> 2019-12-29T00:00:00Z\n",
      "start  <class 'str'> 2019-09-28T00:00:00Z\n",
      "end  2019-12-27T00:00:00Z\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "dt1 = dt.timedelta(days = 2)\n",
    "dt90 = dt.timedelta(days=92)\n",
    "\n",
    "format=\"%Y-%m-%d\"\n",
    "\n",
    "today = dt.datetime.now()\n",
    "end = dt.datetime.now()-dt1\n",
    "start = dt.datetime.now()-dt90\n",
    "\n",
    "print(type(today), today.strftime(format)+\"T00:00:00Z\")\n",
    "print('start ', type(end.strftime(format)), start.strftime(format)+\"T00:00:00Z\")\n",
    "print('end ', end.strftime(format)+\"T00:00:00Z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Gridmet data (as netcdf file) print out some metadata\n",
    "This first bit of code follows examples from the following link:https://climate.northwestknowledge.net/MACA/OPENDAP.php\n",
    "First we open the data set and inspect the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "http://thredds.northwestknowledge.net:8080/thredds/ncss/agg_met_tmmx_1979_CurrentYear_CONUS.nc?var=daily_maximum_temperature&disableLLSubset=on&disableProjSubset=on&horizStride=1&time_start=2019-09-28+13%3A38%3A22.042795&time_end=2019-12-27+13%3A38%3A22.042795&timeStride=1&accept=netcdf\n",
      "<xarray.Dataset>\n",
      "Dimensions:                    (day: 90, lat: 585, lon: 1386)\n",
      "Coordinates:\n",
      "  * day                        (day) datetime64[ns] 2019-09-29 ... 2019-12-27\n",
      "  * lat                        (lat) float64 49.4 49.36 49.32 ... 25.11 25.07\n",
      "  * lon                        (lon) float64 -124.8 -124.7 ... -67.1 -67.06\n",
      "Data variables:\n",
      "    daily_maximum_temperature  (day, lat, lon) float32 ...\n",
      "Attributes:\n",
      "    geospatial_bounds_crs:      EPSG:4326\n",
      "    Conventions:                CF-1.0\n",
      "    geospatial_bounds:          POLYGON((-124.7666666333333 49.40000000000000...\n",
      "    geospatial_lat_min:         25.066666666666666\n",
      "    geospatial_lat_max:         49.400000000000006\n",
      "    geospatial_lon_min:         -124.76666663333334\n",
      "    geospatial_lon_max:         -67.05833330000002\n",
      "    geospatial_lon_resolution:  0.041666666666666\n",
      "    geospatial_lat_resolution:  0.041666666666666\n",
      "    geospatial_lat_units:       decimal_degrees north\n",
      "    geospatial_lon_units:       decimal_degrees east\n",
      "    coordinate_system:          EPSG:4326\n",
      "    author:                     John Abatzoglou - University of Idaho, jabatz...\n",
      "    date:                       02 July 2019\n",
      "    note1:                      The projection information for this file is: ...\n",
      "    note2:                      Citation: Abatzoglou, J.T., 2013, Development...\n",
      "    note3:                      Data in slices after last_permanent_slice (1-...\n",
      "    note4:                      Data in slices after last_provisional_slice (...\n",
      "    note5:                      Days correspond approximately to calendar day...\n",
      "    History:                    Translated to CF-1.0 Conventions by Netcdf-Ja...\n",
      "\n",
      " The meta data is: \n",
      " {\n",
      "    \"geospatial_bounds_crs\": \"EPSG:4326\",\n",
      "    \"Conventions\": \"CF-1.0\",\n",
      "    \"geospatial_bounds\": \"POLYGON((-124.7666666333333 49.400000000000000, -124.7666666333333 25.066666666666666, -67.058333300000015 25.066666666666666, -67.058333300000015 49.400000000000000, -124.7666666333333 49.400000000000000))\",\n",
      "    \"geospatial_lat_min\": 25.066666666666666,\n",
      "    \"geospatial_lat_max\": 49.400000000000006,\n",
      "    \"geospatial_lon_min\": -124.76666663333334,\n",
      "    \"geospatial_lon_max\": -67.05833330000002,\n",
      "    \"geospatial_lon_resolution\": \"0.041666666666666\",\n",
      "    \"geospatial_lat_resolution\": \"0.041666666666666\",\n",
      "    \"geospatial_lat_units\": \"decimal_degrees north\",\n",
      "    \"geospatial_lon_units\": \"decimal_degrees east\",\n",
      "    \"coordinate_system\": \"EPSG:4326\",\n",
      "    \"author\": \"John Abatzoglou - University of Idaho, jabatzoglou@uidaho.edu\",\n",
      "    \"date\": \"02 July 2019\",\n",
      "    \"note1\": \"The projection information for this file is: GCS WGS 1984.\",\n",
      "    \"note2\": \"Citation: Abatzoglou, J.T., 2013, Development of gridded surface meteorological data for ecological applications and modeling, International Journal of Climatology, DOI: 10.1002/joc.3413\",\n",
      "    \"note3\": \"Data in slices after last_permanent_slice (1-based) are considered provisional and subject to change with subsequent updates\",\n",
      "    \"note4\": \"Data in slices after last_provisional_slice (1-based) are considered early and subject to change with subsequent updates\",\n",
      "    \"note5\": \"Days correspond approximately to calendar days ending at midnight, Mountain Standard Time (7 UTC the next calendar day)\",\n",
      "    \"History\": \"Translated to CF-1.0 Conventions by Netcdf-Java CDM (CFGridWriter2)\\nOriginal Dataset = agg_met_tmmx_1979_CurrentYear_CONUS.nc; Translation Date = 2019-12-29T20:56:18.489Z\"\n",
      "}\n",
      "\n",
      " Data attributes, sizes, and coords \n",
      "\n",
      "\n",
      " Data sizes are: \n",
      " Frozen({'day': 90, 'lat': 585, 'lon': 1386})\n",
      "\n",
      " Data coords are: \n",
      " Coordinates:\n",
      "  * day      (day) datetime64[ns] 2019-09-29 2019-09-30 ... 2019-12-27\n",
      "  * lat      (lat) float64 49.4 49.36 49.32 49.28 ... 25.19 25.15 25.11 25.07\n",
      "  * lon      (lon) float64 -124.8 -124.7 -124.7 -124.6 ... -67.14 -67.1 -67.06\n",
      "xarray.core.utils.Frozen\n",
      "90\n",
      "90 1386 585\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.exceptions import HTTPError\n",
    "\n",
    "# delete existing file if it exists\n",
    "exists = os.path.isfile(r'../Data/test3.nc')\n",
    "if exists:\n",
    "#     ds.close()\n",
    "    os.remove(r'../Data/test3.nc')\n",
    "    print('removed existing file')\n",
    "\n",
    "# Url for non-aggragated\n",
    "url = r'http://thredds.northwestknowledge.net:8080/thredds/ncss/MET/tmmn/tmmn_2019.nc'\n",
    "payload={'var': 'air_temperature',\n",
    "        'north': '49.4000',\n",
    "        'west': '-124.7666',\n",
    "        'east': '-67.0583',\n",
    "        'south': '25.0666',\n",
    "        'horizStride': '1',\n",
    "        'time_start': start,\n",
    "        'time_end': end,\n",
    "        'timeStride': '1',\n",
    "        'accept': 'netcdf4'}\n",
    "# Note: when using the non-aggragated server, asking for dates in previous year fails.  Indicates\n",
    "# that using the aggragated server would be the way to go when traversing a new calander year.\n",
    "# http://thredds.northwestknowledge.net:8080/thredds/ncss/agg_met_tmmx_1979_CurrentYear_CONUS.nc?var=daily_maximum_temperature&disableLLSubset=on&disableProjSubset=on&horizStride=1&time_start=2019-01-01T00%3A00%3A00Z&time_end=2019-01-01T00%3A00%3A00Z&timeStride=1&accept=netcdf\n",
    "# Url for aggragated\n",
    "url2 = 'http://thredds.northwestknowledge.net:8080/thredds/ncss/agg_met_tmmx_1979_CurrentYear_CONUS.nc'\n",
    "payload2={'var': 'daily_maximum_temperature',\n",
    "        'disableLLSubset': 'on',\n",
    "        'disableProjSubset': 'on',\n",
    "        'horizStride': '1',\n",
    "        'time_start': start,\n",
    "        'time_end': end,\n",
    "        'timeStride': '1',\n",
    "        'accept': 'netcdf'}\n",
    "# print(url)\n",
    "try:\n",
    "#     myfile = requests.get(url, params=payload)\n",
    "    myfile = requests.get(url2, params=payload2)\n",
    "    myfile.raise_for_status()\n",
    "except HTTPError as http_err:\n",
    "    print(f'HTTP error occurred: {http_err}')  # Python 3.6\n",
    "except Exception as err:\n",
    "    print(f'Other error occurred: {err}')  # Python 3.6\n",
    "else:\n",
    "    print('Success!')\n",
    "#     print(myfile.headers)\n",
    "    print(myfile.url)\n",
    "        \n",
    "with open(r'../Data/test3.nc', 'wb') as fh:\n",
    "    fh.write(myfile.content)\n",
    "    fh.close()\n",
    "\n",
    "ds = xr.open_dataset(r'../Data/test3.nc')\n",
    "print(ds)\n",
    "\n",
    "# df = ds.to_dataframe()\n",
    "\n",
    "print('\\n The meta data is: \\n', json.dumps(ds.attrs, indent=4))\n",
    "lathandle=ds['lat']\n",
    "lonhandle=ds['lon']\n",
    "timehandle=ds['day']\n",
    "# datahandle=ds['air_temperature'] # for non aggragated download\n",
    "datahandle=ds['daily_maximum_temperature'] # for aggragated download\n",
    "# crshandle=ds['crs']\n",
    "# print('\\n The crs meta data is \\n', json.dumps(crshandle.attrs, indent=4))\n",
    "\n",
    "# crstransform = crshandle.attrs['GeoTransform']\n",
    "# print(crstransform)\n",
    "\n",
    "#collect data to describe geotransform\n",
    "lonmin = float(ds.attrs['geospatial_lon_min'])\n",
    "latmax = float(ds.attrs['geospatial_lat_max'])\n",
    "lonres = float(ds.attrs['geospatial_lon_resolution'])\n",
    "latres = float(ds.attrs['geospatial_lon_resolution'])\n",
    "\n",
    "#Print some information on the data\n",
    "\n",
    "print('\\n Data attributes, sizes, and coords \\n') \n",
    "# print('\\n Data attributes are: \\n', json.dumps(datahandle.attrs, indent=4))\n",
    "print('\\n Data sizes are: \\n', datahandle.sizes)\n",
    "print('\\n Data coords are: \\n', datahandle.coords)\n",
    "\n",
    "ts = datahandle.sizes\n",
    "print(type(ts))\n",
    "print(ts['day'])\n",
    "dayshape = ts['day']\n",
    "Lonshape = ts['lon']\n",
    "Latshape = ts['lat']\n",
    "#dayshape,lonshape,latshape = datahandle.values.shape\n",
    "print(dayshape, Lonshape, Latshape)\n",
    "\n",
    "# datahandle.values[dayshape-1,:,:].shape\n",
    "\n",
    "# print(lathandle.values.shape)\n",
    "# print(type(lathandle.values))\n",
    "# print(datahandle.dtype)\n",
    "# print(np.isfortran(datahandle.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp testing and closeing xarray\n",
    "# ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'daily_maximum_temperature' ()>\n",
      "array(nan)\n",
      "Coordinates:\n",
      "    day      datetime64[ns] 2019-04-20\n",
      "    lat      float64 45.07\n",
      "    lon      float64 -73.43\n",
      "Attributes:\n",
      "    units:         K\n",
      "    description:   Daily Maximum Temperature\n",
      "    grid_mapping:  crs\n",
      "    cell_methods:  time: maximum(interval: 24 hours)\n",
      "    height:        2 m\n"
     ]
    }
   ],
   "source": [
    "print(datahandle[dayshape-1, 480, 1232])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add netcdf data (tmax here) to dataframe that has hru id and geometry\n",
    "* use weight file to assign tmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testnan(value, weight):\n",
    "    if np.isnan(value): \n",
    "        tvalue = 0.0\n",
    "        tweight = 0.0\n",
    "    else:\n",
    "        tvalue = value\n",
    "        tweight = weight\n",
    "    return tvalue, tweight\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAYER</th>\n",
       "      <th>GM_TYPE</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>region</th>\n",
       "      <th>hru_id_nat</th>\n",
       "      <th>nhm_id</th>\n",
       "      <th>POI_ID</th>\n",
       "      <th>GFv11_id</th>\n",
       "      <th>hru_segme1</th>\n",
       "      <th>Version</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>geometry</th>\n",
       "      <th>tmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NHM\\nhru_v11</td>\n",
       "      <td>Unknown Area Type</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>76128</td>\n",
       "      <td>76128</td>\n",
       "      <td>5570479.0</td>\n",
       "      <td>76127</td>\n",
       "      <td>40038</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92601.509</td>\n",
       "      <td>188151328</td>\n",
       "      <td>POLYGON ((-97.09917 30.30709, -97.09915 30.307...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NHM\\nhru_v11</td>\n",
       "      <td>Unknown Area Type</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>76148</td>\n",
       "      <td>76148</td>\n",
       "      <td>5570479.0</td>\n",
       "      <td>76147</td>\n",
       "      <td>40038</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60460.683</td>\n",
       "      <td>44161889</td>\n",
       "      <td>POLYGON ((-97.01237 30.32846, -97.01237 30.328...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NHM\\nhru_v11</td>\n",
       "      <td>Unknown Area Type</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>76171</td>\n",
       "      <td>76171</td>\n",
       "      <td>5569089.0</td>\n",
       "      <td>76170</td>\n",
       "      <td>40021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62333.253</td>\n",
       "      <td>73375754</td>\n",
       "      <td>POLYGON ((-97.11149 30.41259, -97.11017 30.411...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NHM\\nhru_v11</td>\n",
       "      <td>Unknown Area Type</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>76171</td>\n",
       "      <td>76171</td>\n",
       "      <td>5569089.0</td>\n",
       "      <td>76170</td>\n",
       "      <td>40021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62333.253</td>\n",
       "      <td>73375754</td>\n",
       "      <td>POLYGON ((-97.06284 30.46034, -97.06283 30.460...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NHM\\nhru_v11</td>\n",
       "      <td>Unknown Area Type</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>76171</td>\n",
       "      <td>76171</td>\n",
       "      <td>5569089.0</td>\n",
       "      <td>76170</td>\n",
       "      <td>40021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62333.253</td>\n",
       "      <td>73375754</td>\n",
       "      <td>POLYGON ((-97.06284 30.46034, -97.06284 30.460...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          LAYER            GM_TYPE  OBJECTID region  hru_id_nat  nhm_id  \\\n",
       "0  NHM\\nhru_v11  Unknown Area Type         1     12       76128   76128   \n",
       "1  NHM\\nhru_v11  Unknown Area Type         2     12       76148   76148   \n",
       "2  NHM\\nhru_v11  Unknown Area Type         3     12       76171   76171   \n",
       "3  NHM\\nhru_v11  Unknown Area Type         3     12       76171   76171   \n",
       "4  NHM\\nhru_v11  Unknown Area Type         3     12       76171   76171   \n",
       "\n",
       "      POI_ID  GFv11_id  hru_segme1  Version  Shape_Leng Shape_Area  \\\n",
       "0  5570479.0     76127       40038      1.0   92601.509  188151328   \n",
       "1  5570479.0     76147       40038      1.0   60460.683   44161889   \n",
       "2  5569089.0     76170       40021      1.0   62333.253   73375754   \n",
       "3  5569089.0     76170       40021      1.0   62333.253   73375754   \n",
       "4  5569089.0     76170       40021      1.0   62333.253   73375754   \n",
       "\n",
       "                                            geometry  tmax  \n",
       "0  POLYGON ((-97.09917 30.30709, -97.09915 30.307...   0.0  \n",
       "1  POLYGON ((-97.01237 30.32846, -97.01237 30.328...   0.0  \n",
       "2  POLYGON ((-97.11149 30.41259, -97.11017 30.411...   0.0  \n",
       "3  POLYGON ((-97.06284 30.46034, -97.06283 30.460...   0.0  \n",
       "4  POLYGON ((-97.06284 30.46034, -97.06284 30.460...   0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(len(data))\n",
    "# print(data.shape)\n",
    "# print(data)\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with Pandas groupby alternative to original method in following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   grid_ids  nhm_id  hru_id_nat         w\n",
      "0    638227   76128       76128  0.030892\n",
      "1    638228   76128       76128  0.011476\n",
      "2    638226   76128       76128  0.094655\n",
      "3    638225   76128       76128  0.095469\n",
      "4    636842   76128       76128  0.017072\n",
      "[nan nan nan ... nan nan nan]\n",
      "139808 113310\n",
      "<class 'numpy.float64'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmcd\\anaconda3\\envs\\ofp_env_upd\\lib\\site-packages\\ipykernel_launcher.py:45: UserWarning: Warning: converting a masked element to nan.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "113594",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-485d5c2cbec4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mtd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mweight_id_rows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_hru_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'nhm_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;31m#     print(weight_id_rows['grid_ids'].values.astype(int))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;31m#     unique_hru_ids.get_group(row['hru_id_nat']).agg({'tmax': np_get_wval(weight_id_rows, ndata)})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ofp_env_upd\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36mget_group\u001b[1;34m(self, name, obj)\u001b[0m\n\u001b[0;32m    678\u001b[0m         \u001b[0minds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 113594"
     ]
    }
   ],
   "source": [
    "# add tmax column to dataframe\n",
    "gdf['tmax']=0.0\n",
    "\n",
    "#open weight data\n",
    "# wght_df = pd.read_csv('../Data/hru_metdata_weights.csv')\n",
    "# wght_df_40 = pd.read_csv('../Data/hru_metdata_weights_40m.csv')\n",
    "# wght_df_500 = pd.read_csv('../Data/hru_metdata_weights_500m.csv')\n",
    "# wght_UofI = pd.read_csv('../Data/hru_uofimetdata_weights.csv')\n",
    "wght_UofI = pd.read_csv('../Data_v1_1/gridmet_weights_hru_v1_1.csv')\n",
    "# print(len(wght_df['hru_id_nat'].unique()), len(wght_df_40['hru_id_nat'].unique()), \n",
    "#       len(wght_df_500['hru_id_nat'].unique()), len(wght_UofI['hru_id_nat'].unique()))\n",
    "print(wght_UofI.head())\n",
    "\n",
    "#iterate through hru's, grab all weights associated with hru_id, get total weighted value from netcdf file, assign to tmax\n",
    "ndata = datahandle.values[dayshape-1,:,:].flatten(order='K')\n",
    "# ndata=np.nan_to_num(data)\n",
    "print(ndata[1000:])\n",
    "# def w_mean(data)\n",
    "unique_hru_ids = wght_UofI.groupby('nhm_id')\n",
    "print(len(gdf), len(unique_hru_ids))\n",
    "\n",
    "def get_wval(grp, ndata):\n",
    "    ttmax = twght = 0.0\n",
    "    for index, row in grp.iterrows():\n",
    "        ttmax += row['w']*ndata[np.int(row['grid_ids'])]\n",
    "        twght += row['w']\n",
    "    return ttmax/twght\n",
    "def np_get_wval(grp, ndata):\n",
    "    return np.average(ndata[grp['grid_ids'].values.astype(int)], weights=grp['w'])\n",
    "def np_get_wval2(grp, ndata):\n",
    "    mdata = np.ma.masked_array(ndata[grp['grid_ids'].values.astype(int)], np.isnan(ndata[grp['grid_ids'].values.astype(int)]))\n",
    "    return np.ma.average(mdata, weights=grp['w'])\n",
    "#     return np.average(ndata[grp['grid_ids'].values.astype(int)], weights=grp['w'])\n",
    "    \n",
    "# unique_hru_ids.get_group(gdf['hru_id_nat']).agg({'tmax': np_get_wval(weight_id_rows, ndata)})    \n",
    "td = np.zeros(len(gdf.index))\n",
    "for index, row in gdf.iterrows():\n",
    "    weight_id_rows = unique_hru_ids.get_group(row['nhm_id'])\n",
    "#     print(weight_id_rows['grid_ids'].values.astype(int))\n",
    "#     unique_hru_ids.get_group(row['hru_id_nat']).agg({'tmax': np_get_wval(weight_id_rows, ndata)})\n",
    "#     gdf.loc[gdf.index[index],'tmax'] = np_get_wval(weight_id_rows, ndata)-273.5\n",
    "    tmp = np_get_wval2(weight_id_rows, ndata)-273.5\n",
    "    if index == 1:\n",
    "        print(type(tmp))\n",
    "    td[index] = np_get_wval2(weight_id_rows, ndata)-273.5\n",
    "#     if td[index] < 0.0:\n",
    "#         print(ndata[weight_id_rows['grid_ids'].values.astype(int)], weight_id_rows['w'])\n",
    "#     print(index, td[index])\n",
    "#     if row['hru_id_nat'] == 829:\n",
    "#         print(\"in test\")\n",
    "#         for i2, el in weight_id_rows.iterrows():\n",
    "#             print(el['w'], ndata[el['grid_ids'].astype(int)])\n",
    "#         print(np.average(ndata[weight_id_rows['grid_ids'].values.astype(int)], weights=weight_id_rows['w'])-273.5)\n",
    "#     print(index, row['hru_id_nat'], np_get_wval(weight_id_rows, ndata)-273.5)\n",
    "#     gdf.loc[gdf.index[index], 'tmax'] =\n",
    "# #     print(get_wval(weight_id_rows, ndata)-273.5)\n",
    "# #     row.loc['tmax']=get_wval(weight_id_rows, ndata)-273.5\n",
    "# #     gdf.loc[gdf.index[index], 'tmax'] = get_wval(weight_id_rows, ndata)-273.5\n",
    "# print(len(td))\n",
    "# gdf['tmax'] = gpd.GeoSeries([np.transpose(td)], index=gdf.index)\n",
    "gdf['tmax'] = td.tolist()\n",
    "gdf['tmax'].fillna(0.0)\n",
    "# print(td.tolist())\n",
    "print('min/max', gdf['tmax'].min(), gdf['tmax'].max())\n",
    "# print(gdf)\n",
    "# gdf.plot(figsize=(12,12), column = 'tmax',linewidth=0.25, edgecolor='white')    \n",
    "# print(gdf.groupby(tmax).min)\n",
    "f, ax = plt.subplots(2, figsize=(12,12))\n",
    "gdf.plot(ax=ax[0], column = 'tmax',linewidth=0., edgecolor='white', scheme='quantiles')\n",
    "ptmax = ds.daily_maximum_temperature-273.5\n",
    "ptmax_1 = ptmax.isel(day=dayshape-1)\n",
    "lvs = np.arange(gdf['tmax'].min(), gdf['tmax'].max(), 0.5)\n",
    "ptmax_1.plot(ax=ax[1], levels=lvs, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94965\n",
      "LAYER                                              NHM\\nhru_v11\n",
      "GM_TYPE                                       Unknown Area Type\n",
      "OBJECTID                                                  77459\n",
      "region                                                     0904\n",
      "hru_id_nat                                                    0\n",
      "nhm_id                                                   113594\n",
      "POI_ID                                           65000400000870\n",
      "GFv11_id                                                  96255\n",
      "hru_segme1                                                30828\n",
      "Version                                                     1.1\n",
      "Shape_Leng                                                70016\n",
      "Shape_Area                                             75992086\n",
      "geometry      POLYGON ((-113.2720572946257 49.52878439413107...\n",
      "tmax                                                          0\n",
      "Name: 94965, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "113594"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_hru_ids.head()\n",
    "print(index)\n",
    "print(row)\n",
    "row['nhm_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmcd\\GitRepos\\Python Projects\\onhm-fetcher-parser\\notebooks\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must be a 2D or 3D array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-dc27c1917763>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m stats = zonal_stats(hrudata, datahandle.values[dayshape-1,:,:].flatten(order='K'), \n\u001b[0;32m     20\u001b[0m                     \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_gdal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tmax_'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m                     all_touched=True, geojson_out=True)\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;31m# statsdf = pd.DataFrame(stats)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# src.close()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gridmet_4\\lib\\site-packages\\rasterstats\\main.py\u001b[0m in \u001b[0;36mzonal_stats\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0monly\u001b[0m \u001b[0mdifference\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mthat\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzonal_stats\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mwill\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     return a list rather than a generator.\"\"\"\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_zonal_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gridmet_4\\lib\\site-packages\\rasterstats\\main.py\u001b[0m in \u001b[0;36mgen_zonal_stats\u001b[1;34m(vectors, raster, layer, band, nodata, affine, stats, all_touched, categorical, category_map, add_stats, zone_func, raster_out, prefix, geojson_out, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m             \u001b[0mgeom_bounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m             \u001b[0mfsrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgeom_bounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;31m# rasterized geometry\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gridmet_4\\lib\\site-packages\\rasterstats\\io.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, bounds, window, masked)\u001b[0m\n\u001b[0;32m    303\u001b[0m             \u001b[1;31m# It's an ndarray already\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             new_array = boundless_array(\n\u001b[1;32m--> 305\u001b[1;33m                 self.array, window=win, nodata=nodata, masked=masked)\n\u001b[0m\u001b[0;32m    306\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m             \u001b[1;31m# It's an open rasterio dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gridmet_4\\lib\\site-packages\\rasterstats\\io.py\u001b[0m in \u001b[0;36mboundless_array\u001b[1;34m(arr, window, nodata, masked)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[0mdim3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Must be a 2D or 3D array\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;31m# unpack for readability\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Must be a 2D or 3D array"
     ]
    }
   ],
   "source": [
    "# Alternative Rasterstats by opening netcdf directly rather than first saving to geotif\n",
    "import rasterio\n",
    "import rasterio.plot as rioplot\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "print(os.getcwd())\n",
    "transform = from_origin( lonmin, latmax, lonres, latres)\n",
    "# with rasterio.open(r'../Data/new.nc', driver='NetCDF') as src:\n",
    "#     transformb = src.meta['transform']\n",
    "#     print(type(transformb), src.meta)\n",
    "#     array = src.read(1)\n",
    "# rasterdata = rasterio.open(r'test1.tif')\n",
    "# tmp = rioplot.show(rasterdata, with_bounds=True, cmap='viridis', extent=([-82, -70, 36, 46]))\n",
    "# print(tmp.axis)\n",
    "# tmp.set_xlim([-82, -70])\n",
    "# tmp.set_ylim([36, 46])\n",
    "hrudata = gpd.GeoDataFrame.from_file(r'../Data/nhru_02.shp')\n",
    "\n",
    "stats = zonal_stats(hrudata, datahandle.values[dayshape-1,:,:].flatten(order='K'), \n",
    "                    transform=transform.to_gdal(), prefix='tmax_', \n",
    "                    all_touched=True, geojson_out=True)\n",
    "# statsdf = pd.DataFrame(stats)\n",
    "# src.close()\n",
    "stats_gdf = gpd.GeoDataFrame.from_features(stats)\n",
    "print(stats_gdf.head())\n",
    "extent=([-82, -70, 36, 46])\n",
    "f, ax = plt.subplots(1, figsize=(8,6))\n",
    "ax.set_title(\"max temp\")\n",
    "stats_gdf.plot(ax=ax, column='tmax_mean', scheme='Equal_Interval', k=10, \n",
    "                   cmap='viridis', linewidth=0.25, edgecolor='black', \n",
    "                   legend=True, legend_kwds={'loc': 'upper left'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write netcdf file using netcdf4\n",
    "* https://github.com/Unidata/netcdf4-python/blob/master/examples/writing_netCDF.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('hruid', <class 'netCDF4._netCDF4.Dimension'>: name = 'hruid', size = 7289\n",
      ")\n",
      "('time', <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0\n",
      ")\n",
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF3_CLASSIC data model, file format NETCDF3):\n",
      "    Conventions: CF-1.8\n",
      "    featureType: timeSeries\n",
      "    history: \n",
      "    dimensions(sizes): hruid(7289), time(1)\n",
      "    variables(dimensions): int32 \u001b[4mtime\u001b[0m(time), int32 \u001b[4mhruid\u001b[0m(hruid), float32 \u001b[4mhru_lat\u001b[0m(hruid), float32 \u001b[4mhru_lon\u001b[0m(hruid), float32 \u001b[4mprcp\u001b[0m(time,hruid), float32 \u001b[4mtmax\u001b[0m(time,hruid), float32 \u001b[4mtmin\u001b[0m(time,hruid)\n",
      "    groups: \n",
      "\n",
      "dataset is closed\n"
     ]
    }
   ],
   "source": [
    "import netCDF4\n",
    "try: ncfile.close() # just to be safe, make sure dataset is not already open.\n",
    "except: pass\n",
    "# ncfile = netCDF4.Dataset('new.nc',mode='w',format='NETCDF3_CLASSIC')\n",
    "ncfile = netCDF4.Dataset('new.nc',mode='w',format='NETCDF4_CLASSIC')\n",
    "# Global Attributes\n",
    "ncfile.Conventions = 'CF-1.8'\n",
    "ncfile.featureType = 'timeSeries'\n",
    "ncfile.history = ''\n",
    "\n",
    "sp_dim = len(gdf.index)\n",
    "hruid_dim = ncfile.createDimension('hruid', sp_dim)     # hru_id\n",
    "time_dim = ncfile.createDimension('time', None) # unlimited axis (can be appended to).\n",
    "for dim in ncfile.dimensions.items():\n",
    "    print(dim)\n",
    "\n",
    "#Create Variables\n",
    "time = ncfile.createVariable('time', np.int, ('time', ))\n",
    "time.long_name = 'time'\n",
    "time.standard_name = 'time'\n",
    "time.units = 'days since '+'base_date'+' 00:00'+'time_zone'\n",
    "\n",
    "hru = ncfile.createVariable('hruid', np.int, ('hruid', ))\n",
    "hru.cf_role = 'timeseries_id'\n",
    "hru.long_name = 'local model hru id'\n",
    "\n",
    "lat = ncfile.createVariable('hru_lat', np.float32, ('hruid',))\n",
    "lat.long_name = 'Latitude of HRU centroid'\n",
    "lat.units = 'degrees_north'\n",
    "lat.standard_name = 'hru_latitude'\n",
    "\n",
    "lon = ncfile.createVariable('hru_lon', np.float32, ('hruid',))\n",
    "lon.long_name = 'Longitude of HRU centroid'\n",
    "lon.units = 'degrees_east'\n",
    "lon.standard_name = 'hru_longitude'\n",
    "\n",
    "prcp = ncfile.createVariable('prcp', np.float32, ('time', 'hruid'))\n",
    "prcp.long_name = 'Daily precipitation rate'\n",
    "prcp.units = 'mm/day'\n",
    "prcp.standard_name = 'lwe_precipitation_rate'\n",
    "\n",
    "tmax = ncfile.createVariable('tmax', np.float32, ('time', 'hruid'))\n",
    "tmax.long_name = 'Maximum daily air temperature'\n",
    "tmax.units = 'degree_Celsius'\n",
    "tmax.standard_name = 'maximum_daily_air_temperature'\n",
    "\n",
    "tmin = ncfile.createVariable('tmin', np.float32, ('time', 'hruid'))\n",
    "tmin.long_name = 'Minimum daily air temperature'\n",
    "tmin.units = 'degree_Celsius'\n",
    "tmin.standard_name = 'minimum_daily_air_temperature'\n",
    "\n",
    "# fill variables with available data\n",
    "def getXY(pt):\n",
    "    return (pt.x, pt.y)\n",
    "centroidseries = gdf['geometry'].centroid\n",
    "tlon, tlat = [list(t) for t  in zip(*map(getXY, centroidseries))]\n",
    "# print(lon, lat)\n",
    "lon[:] = tlon\n",
    "lat[:] = tlat\n",
    "hru[:] = gdf['hru_id_nat'].values\n",
    "# print(hruid)\n",
    "tmax[0,:] = gdf['tmax'].values\n",
    "\n",
    "print(ncfile)\n",
    "ncfile.close(); print(\"dataset is closed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
